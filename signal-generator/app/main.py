"""
Signal Generator Service

Main entry point for the signal generator service.
Runs configured signal generators and emits signals to stdout (Phase 1)
or Kafka (Phase 2).
"""
import asyncio
import json
import time
from datetime import datetime
from typing import List, Optional
import structlog
from kafka import KafkaProducer
from kafka.errors import KafkaError

from app.config import settings
from app.generators import (
    get_registry,
    MockSignalGenerator,
    GoldenCrossSignalGenerator,
    DeathCrossSignalGenerator,
    RSISignalGenerator,
    MACDSignalGenerator,
    VolumeSpikeSignalGenerator,
    BollingerBandsSignalGenerator,
    StochasticSignalGenerator,
    ADXSignalGenerator,
    EMACrossoverSignalGenerator,
    ATRSignalGenerator,
    CCISignalGenerator,
    StochRSISignalGenerator,
    WilliamsRSignalGenerator,
    AroonSignalGenerator,
    MFISignalGenerator,
    OBVSignalGenerator,
    SARSignalGenerator
)
from app.schemas.signal import Signal
from app.telemetry import setup_telemetry


# Configure structured logging
structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.add_log_level,
        structlog.processors.JSONRenderer()
    ]
)

logger = structlog.get_logger()


class SignalGeneratorService:
    """
    Signal generator service that runs multiple generators.
    
    In Phase 1, signals are emitted to stdout/logs.
    In Phase 2, signals are published to Kafka.
    """
    
    def __init__(self):
        """Initialize the service with configured generators."""
        self.registry = get_registry()
        self.generators = []
        self.running = False
        self.kafka_producer: Optional[KafkaProducer] = None
        
        # Initialize telemetry
        try:
            self.meter = setup_telemetry(service_name="signal-generator")
            self._setup_metrics()
            logger.info("telemetry_initialized")
        except Exception as e:
            logger.error("telemetry_initialization_failed", error=str(e))
            self.meter = None
        
        # Initialize Kafka producer
        self._initialize_kafka()
    
    def _setup_metrics(self):
        """Setup custom metrics."""
        if not self.meter:
            return
        
        # Signal generation metrics
        self.signals_generated = self.meter.create_counter(
            "signals_generated_total",
            description="Total signals generated by generator and signal type"
        )
        
        self.signal_generation_duration = self.meter.create_histogram(
            "signal_generation_duration_seconds",
            description="Time taken to generate signals by generator"
        )
        
        # Generator scan metrics
        self.generator_scans_total = self.meter.create_counter(
            "generator_scans_total",
            description="Total number of scans per generator"
        )
        
        self.generator_scan_errors = self.meter.create_counter(
            "generator_scan_errors_total",
            description="Total scan errors per generator"
        )
        
        # Kafka metrics
        self.kafka_publish_duration = self.meter.create_histogram(
            "kafka_publish_duration_seconds",
            description="Time taken to publish signal to Kafka"
        )
        
        self.kafka_publish_success = self.meter.create_counter(
            "kafka_publish_success_total",
            description="Total successful Kafka publishes by signal type"
        )
        
        self.kafka_publish_failure = self.meter.create_counter(
            "kafka_publish_failure_total",
            description="Total failed Kafka publishes by signal type"
        )
        
        # Finnhub API metrics
        self.finnhub_api_calls = self.meter.create_counter(
            "finnhub_api_calls_total",
            description="Total Finnhub API calls by indicator type"
        )
        
        self.finnhub_api_errors = self.meter.create_counter(
            "finnhub_api_errors_total",
            description="Total Finnhub API errors by error type"
        )
        
        # Initialize generators based on configuration
        self._initialize_generators()
    
    def _initialize_kafka(self):
        """Initialize Kafka producer for signal publishing."""
        try:
            self.kafka_producer = KafkaProducer(
                bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS,
                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                key_serializer=lambda k: k.encode('utf-8') if k else None,
                acks='all',  # Wait for all replicas to acknowledge
                retries=3,
                max_in_flight_requests_per_connection=1  # Ensure ordering
            )
            logger.info(
                "kafka_producer_initialized",
                bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS,
                topic=settings.KAFKA_SIGNAL_TOPIC
            )
        except Exception as e:
            logger.error(
                "kafka_producer_initialization_failed",
                error=str(e),
                exc_info=True
            )
            self.kafka_producer = None
            logger.warning("signals_will_only_log", message="Kafka unavailable, falling back to logs only")
    
    def _initialize_generators(self):
        """Initialize all configured generators."""
        watchlist = settings.get_watchlist()
        
        # Mock generator (for testing)
        from app.schemas.signal import BiasType
        
        mock_config = {
            "tickers": watchlist[:3],  # First 3 tickers
            "emission_probability": 0.3,
            "bias_options": [BiasType.BULLISH, BiasType.BEARISH]
        }
        self.generators.append({
            "name": "mock",
            "generator": MockSignalGenerator(mock_config),
            "interval": settings.MOCK_GENERATOR_INTERVAL_SECONDS
        })
        
        # Golden cross generator
        golden_cross_config = {
            "tickers": watchlist,
            "sma_short": settings.GOLDEN_CROSS_SMA_SHORT,
            "sma_long": settings.GOLDEN_CROSS_SMA_LONG,
            "timeframe": settings.GOLDEN_CROSS_TIMEFRAME,
            "lookback_days": 5,
            "confidence": 0.85
        }
        self.generators.append({
            "name": "golden_cross",
            "generator": GoldenCrossSignalGenerator(golden_cross_config),
            "interval": settings.GOLDEN_CROSS_CHECK_INTERVAL_SECONDS
        })
        
        # Death cross generator
        death_cross_config = {
            "tickers": watchlist,
            "sma_short": settings.DEATH_CROSS_SMA_SHORT,
            "sma_long": settings.DEATH_CROSS_SMA_LONG,
            "timeframe": settings.DEATH_CROSS_TIMEFRAME,
            "lookback_days": 5,
            "confidence": 0.85
        }
        self.generators.append({
            "name": "death_cross",
            "generator": DeathCrossSignalGenerator(death_cross_config),
            "interval": settings.DEATH_CROSS_CHECK_INTERVAL_SECONDS
        })
        
        # RSI generator
        rsi_config = {
            "tickers": watchlist,
            "period": settings.RSI_PERIOD,
            "oversold_threshold": settings.RSI_OVERSOLD_THRESHOLD,
            "overbought_threshold": settings.RSI_OVERBOUGHT_THRESHOLD,
            "timeframe": settings.RSI_TIMEFRAME,
            "confidence": 0.75
        }
        self.generators.append({
            "name": "rsi",
            "generator": RSISignalGenerator(rsi_config),
            "interval": settings.RSI_CHECK_INTERVAL_SECONDS
        })
        
        # MACD generator
        macd_config = {
            "tickers": watchlist,
            "fast_period": settings.MACD_FAST_PERIOD,
            "slow_period": settings.MACD_SLOW_PERIOD,
            "signal_period": settings.MACD_SIGNAL_PERIOD,
            "timeframe": settings.MACD_TIMEFRAME,
            "confidence": 0.80,
            "require_histogram_confirmation": True
        }
        self.generators.append({
            "name": "macd",
            "generator": MACDSignalGenerator(macd_config),
            "interval": settings.MACD_CHECK_INTERVAL_SECONDS
        })
        
        # Volume Spike generator
        volume_spike_config = {
            "tickers": watchlist,
            "volume_period": settings.VOLUME_SPIKE_PERIOD,
            "spike_threshold": settings.VOLUME_SPIKE_THRESHOLD,
            "timeframe": settings.VOLUME_SPIKE_TIMEFRAME,
            "confidence": 0.70,
            "use_price_direction": True,
            "min_price_change_pct": 1.0
        }
        self.generators.append({
            "name": "volume_spike",
            "generator": VolumeSpikeSignalGenerator(volume_spike_config),
            "interval": settings.VOLUME_SPIKE_CHECK_INTERVAL_SECONDS
        })
        
        # Bollinger Bands generator
        bbands_config = {
            "tickers": watchlist,
            "timeperiod": settings.BBANDS_TIMEPERIOD,
            "nbdevup": settings.BBANDS_NBDEVUP,
            "nbdevdn": settings.BBANDS_NBDEVDN,
            "timeframe": settings.BBANDS_TIMEFRAME,
            "confidence": 0.75,
            "signal_type": settings.BBANDS_SIGNAL_TYPE
        }
        self.generators.append({
            "name": "bollinger_bands",
            "generator": BollingerBandsSignalGenerator(bbands_config),
            "interval": settings.BBANDS_CHECK_INTERVAL_SECONDS
        })
        
        # Stochastic generator
        stoch_config = {
            "tickers": watchlist,
            "fastk_period": settings.STOCH_FASTK_PERIOD,
            "slowk_period": settings.STOCH_SLOWK_PERIOD,
            "slowd_period": settings.STOCH_SLOWD_PERIOD,
            "overbought": settings.STOCH_OVERBOUGHT,
            "oversold": settings.STOCH_OVERSOLD,
            "timeframe": settings.STOCH_TIMEFRAME,
            "confidence": 0.75
        }
        self.generators.append({
            "name": "stochastic",
            "generator": StochasticSignalGenerator(stoch_config),
            "interval": settings.STOCH_CHECK_INTERVAL_SECONDS
        })
        
        # ADX generator
        adx_config = {
            "tickers": watchlist,
            "timeperiod": settings.ADX_TIMEPERIOD,
            "strong_trend": settings.ADX_STRONG_TREND,
            "weak_trend": settings.ADX_WEAK_TREND,
            "timeframe": settings.ADX_TIMEFRAME,
            "confidence": 0.70
        }
        self.generators.append({
            "name": "adx",
            "generator": ADXSignalGenerator(adx_config),
            "interval": settings.ADX_CHECK_INTERVAL_SECONDS
        })
        
        # EMA Crossover generator
        ema_config = {
            "tickers": watchlist,
            "ema_fast": settings.EMA_FAST,
            "ema_slow": settings.EMA_SLOW,
            "timeframe": settings.EMA_TIMEFRAME,
            "lookback_days": 5,
            "confidence": 0.80
        }
        self.generators.append({
            "name": "ema_crossover",
            "generator": EMACrossoverSignalGenerator(ema_config),
            "interval": settings.EMA_CHECK_INTERVAL_SECONDS
        })
        
        # ATR generator
        atr_config = {
            "tickers": watchlist,
            "timeperiod": settings.ATR_TIMEPERIOD,
            "spike_multiplier": settings.ATR_SPIKE_MULTIPLIER,
            "compression_multiplier": settings.ATR_COMPRESSION_MULTIPLIER,
            "lookback_for_average": settings.ATR_LOOKBACK_FOR_AVERAGE,
            "timeframe": settings.ATR_TIMEFRAME,
            "confidence": 0.65
        }
        self.generators.append({
            "name": "atr",
            "generator": ATRSignalGenerator(atr_config),
            "interval": settings.ATR_CHECK_INTERVAL_SECONDS
        })
        
        # CCI generator
        cci_config = {
            "tickers": watchlist,
            "timeperiod": settings.CCI_TIMEPERIOD,
            "overbought": settings.CCI_OVERBOUGHT,
            "oversold": settings.CCI_OVERSOLD,
            "timeframe": settings.CCI_TIMEFRAME,
            "confidence": 0.70
        }
        self.generators.append({
            "name": "cci",
            "generator": CCISignalGenerator(cci_config),
            "interval": settings.CCI_CHECK_INTERVAL_SECONDS
        })
        
        # Stochastic RSI generator
        stochrsi_config = {
            "tickers": watchlist,
            "timeperiod": settings.STOCHRSI_TIMEPERIOD,
            "fastk_period": settings.STOCHRSI_FASTK_PERIOD,
            "fastd_period": settings.STOCHRSI_FASTD_PERIOD,
            "overbought": settings.STOCHRSI_OVERBOUGHT,
            "oversold": settings.STOCHRSI_OVERSOLD,
            "timeframe": settings.STOCHRSI_TIMEFRAME,
            "confidence": 0.75
        }
        self.generators.append({
            "name": "stochrsi",
            "generator": StochRSISignalGenerator(stochrsi_config),
            "interval": settings.STOCHRSI_CHECK_INTERVAL_SECONDS
        })
        
        # Williams %R generator
        willr_config = {
            "tickers": watchlist,
            "timeperiod": settings.WILLR_TIMEPERIOD,
            "overbought": settings.WILLR_OVERBOUGHT,
            "oversold": settings.WILLR_OVERSOLD,
            "timeframe": settings.WILLR_TIMEFRAME,
            "confidence": 0.70
        }
        self.generators.append({
            "name": "williams_r",
            "generator": WilliamsRSignalGenerator(willr_config),
            "interval": settings.WILLR_CHECK_INTERVAL_SECONDS
        })
        
        # AROON generator
        aroon_config = {
            "tickers": watchlist,
            "timeperiod": settings.AROON_TIMEPERIOD,
            "trend_threshold": settings.AROON_TREND_THRESHOLD,
            "timeframe": settings.AROON_TIMEFRAME,
            "confidence": 0.75
        }
        self.generators.append({
            "name": "aroon",
            "generator": AroonSignalGenerator(aroon_config),
            "interval": settings.AROON_CHECK_INTERVAL_SECONDS
        })
        
        # MFI generator
        mfi_config = {
            "tickers": watchlist,
            "timeperiod": settings.MFI_TIMEPERIOD,
            "overbought": settings.MFI_OVERBOUGHT,
            "oversold": settings.MFI_OVERSOLD,
            "timeframe": settings.MFI_TIMEFRAME,
            "confidence": 0.75
        }
        self.generators.append({
            "name": "mfi",
            "generator": MFISignalGenerator(mfi_config),
            "interval": settings.MFI_CHECK_INTERVAL_SECONDS
        })
        
        # OBV generator
        obv_config = {
            "tickers": watchlist,
            "sma_period": settings.OBV_SMA_PERIOD,
            "divergence_lookback": settings.OBV_DIVERGENCE_LOOKBACK,
            "min_price_change": settings.OBV_MIN_PRICE_CHANGE,
            "timeframe": settings.OBV_TIMEFRAME,
            "confidence": 0.70
        }
        self.generators.append({
            "name": "obv",
            "generator": OBVSignalGenerator(obv_config),
            "interval": settings.OBV_CHECK_INTERVAL_SECONDS
        })
        
        # SAR generator
        sar_config = {
            "tickers": watchlist,
            "acceleration": settings.SAR_ACCELERATION,
            "maximum": settings.SAR_MAXIMUM,
            "timeframe": settings.SAR_TIMEFRAME,
            "confidence": 0.75
        }
        self.generators.append({
            "name": "sar",
            "generator": SARSignalGenerator(sar_config),
            "interval": settings.SAR_CHECK_INTERVAL_SECONDS
        })
        
        logger.info(
            "generators_initialized",
            count=len(self.generators),
            generators=[g["name"] for g in self.generators]
        )
    
    async def run_generator(self, generator_info: dict):
        """
        Run a single generator in a loop.
        
        Args:
            generator_info: Dict with generator, interval, and name
        """
        generator = generator_info["generator"]
        interval = generator_info["interval"]
        name = generator_info["name"]
        
        logger.info(
            "generator_started",
            generator=name,
            interval_seconds=interval
        )
        
        while self.running:
            try:
                # Track scan
                if self.meter:
                    self.generator_scans_total.add(1, {"generator": name})
                
                # Track generation time
                start_time = time.time()
                
                # Generate signals
                signals = await generator.generate()
                
                # Record generation duration (even if no signals)
                if self.meter:
                    gen_duration = time.time() - start_time
                    self.signal_generation_duration.record(
                        gen_duration,
                        {"generator": name}
                    )
                
                if signals:
                    # Emit signals
                    await self._emit_signals(signals, generator_name=name)
                
            except Exception as e:
                # Track error
                if self.meter:
                    self.generator_scan_errors.add(1, {
                        "generator": name,
                        "error_type": type(e).__name__
                    })
                
                logger.error(
                    "generator_error",
                    generator=name,
                    error=str(e),
                    exc_info=True
                )
            
            # Wait for next interval
            await asyncio.sleep(interval)
    
    async def _emit_signals(self, signals: List[Signal], generator_name: str = None):
        """
        Emit signals to output.
        
        Phase 1: Log to stdout/file
        Phase 2: Publish to Kafka
        
        Args:
            signals: List of signals to emit
            generator_name: Name of the generator that produced signals
        """
        for signal in signals:
            # Convert to Kafka-ready format
            message = signal.to_kafka_message()
            
            # Track metrics
            if self.meter:
                self.signals_generated.add(1, {
                    "signal_type": signal.signal_type.value,
                    "source": signal.source,
                    "generator": generator_name or signal.source
                })
            
            # Phase 2: Publish to Kafka
            if self.kafka_producer:
                publish_start = time.time()
                try:
                    # Use signal_type as the key for partitioning
                    key = signal.signal_type.value
                    
                    future = self.kafka_producer.send(
                        settings.KAFKA_SIGNAL_TOPIC,
                        key=key,
                        value=message
                    )
                    
                    # Wait for acknowledgment (with timeout)
                    record_metadata = future.get(timeout=10)
                    
                    # Record successful publish
                    if self.meter:
                        publish_duration = time.time() - publish_start
                        self.kafka_publish_duration.record(publish_duration, {
                            "signal_type": signal.signal_type.value
                        })
                        self.kafka_publish_success.add(1, {
                            "signal_type": signal.signal_type.value
                        })
                    
                    logger.info(
                        "signal_published_to_kafka",
                        signal_id=str(signal.signal_id),
                        topic=record_metadata.topic,
                        partition=record_metadata.partition,
                        offset=record_metadata.offset
                    )
                except KafkaError as e:
                    # Record failed publish
                    if self.meter:
                        self.kafka_publish_failure.add(1, {
                            "signal_type": signal.signal_type.value,
                            "error_type": type(e).__name__
                        })
                    
                    logger.error(
                        "kafka_publish_failed",
                        signal_id=str(signal.signal_id),
                        error=str(e),
                        exc_info=True
                    )
                except Exception as e:
                    # Record failed publish
                    if self.meter:
                        self.kafka_publish_failure.add(1, {
                            "signal_type": signal.signal_type.value,
                            "error_type": type(e).__name__
                        })
                    
                    logger.error(
                        "unexpected_kafka_error",
                        signal_id=str(signal.signal_id),
                        error=str(e),
                        exc_info=True
                    )
            
            # Also log the signal (structured logging)
            logger.info(
                "signal_emitted",
                signal_id=str(signal.signal_id),
                signal_type=signal.signal_type.value,
                source=signal.source,
                timestamp=int(signal.timestamp.timestamp()),
                tickers=[
                    {
                        "ticker": ts.ticker,
                        "signal": ts.signal.value,
                        "confidence": ts.confidence
                    }
                    for ts in signal.tickers
                ]
            )
            
            # Also print to stdout in a nice format for visibility
            print("\n" + "="*80)
            print(f"ðŸ”” SIGNAL GENERATED: {signal.signal_type.value.upper()}")
            print(f"   ID: {signal.signal_id}")
            print(f"   Source: {signal.source}")
            print(f"   Timestamp: {signal.timestamp.strftime('%Y-%m-%d %H:%M:%S UTC')}")
            
            if self.kafka_producer:
                print(f"   ðŸ“¤ Published to Kafka: {settings.KAFKA_SIGNAL_TOPIC}")
            
            print(f"   Tickers:")
            
            for ticker_signal in signal.tickers:
                print(f"     â€¢ {ticker_signal.ticker}: {ticker_signal.signal.value} (confidence: {ticker_signal.confidence:.0f}%)")
                if ticker_signal.reasoning:
                    print(f"       â†’ {ticker_signal.reasoning}")
            
            if signal.metadata:
                print(f"   Metadata: {json.dumps(signal.metadata, indent=6)}")
            
            print("="*80 + "\n")
    
    async def start(self):
        """Start all generators."""
        self.running = True
        
        logger.info(
            "signal_generator_service_starting",
            service=settings.SERVICE_NAME,
            generators=len(self.generators)
        )
        
        print(f"\nðŸš€ Signal Generator Service Starting...")
        print(f"   Generators: {len(self.generators)}")
        print(f"   Watchlist: {settings.get_watchlist()}")
        print(f"   Log Level: {settings.LOG_LEVEL}\n")
        
        # Start all generators as concurrent tasks
        tasks = [
            asyncio.create_task(self.run_generator(gen_info))
            for gen_info in self.generators
        ]
        
        # Wait for all tasks (runs indefinitely until interrupted)
        try:
            await asyncio.gather(*tasks)
        except asyncio.CancelledError:
            logger.info("signal_generator_service_cancelled")
            raise
    
    async def stop(self):
        """Stop all generators and cleanup resources."""
        self.running = False
        
        # Close Kafka producer
        if self.kafka_producer:
            try:
                self.kafka_producer.flush(timeout=5)
                self.kafka_producer.close(timeout=5)
                logger.info("kafka_producer_closed")
            except Exception as e:
                logger.error("kafka_producer_close_error", error=str(e))
        
        logger.info("signal_generator_service_stopping")
        print("\nðŸ›‘ Signal Generator Service Stopping...\n")


async def main():
    """Main entry point."""
    service = SignalGeneratorService()
    
    try:
        await service.start()
    except KeyboardInterrupt:
        logger.info("keyboard_interrupt_received")
        await service.stop()
    except Exception as e:
        logger.error("service_crashed", error=str(e), exc_info=True)
        await service.stop()
        raise


if __name__ == "__main__":
    asyncio.run(main())

